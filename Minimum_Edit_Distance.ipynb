{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLZeAKLp90Pp"
   },
   "outputs": [],
   "source": [
    "!unzip 0643.zip -d birbeck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "GDMA5HVuRW5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytrec-eval-terrier in c:\\users\\vanam\\anaconda3\\lib\\site-packages (0.5.2)\n"
     ]
    }
   ],
   "source": [
    "# download libraries\n",
    "\n",
    "!pip install pytrec-eval-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "9liVG8G_5ZRu"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "import multiprocessing\n",
    "import time\n",
    "import collections\n",
    "import numpy\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import pytrec_eval\n",
    "from operator import itemgetter\n",
    "from collections import OrderedDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vanam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download Wordnet dictionary\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "xo_K1FjcSOAb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sad said',\n",
       " 'sweety sweaty',\n",
       " 'dreamd dreamed',\n",
       " 'stayd stayed',\n",
       " 'fellt felt',\n",
       " 'litlle little',\n",
       " 'nexst next',\n",
       " 'satt sat',\n",
       " 'weeckend weekend',\n",
       " 'catsh catch']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the words in Birbeck corpus in pairs of incorrect and correct spellings\n",
    "\n",
    "f = open(\"/content/birbeck/ABODAT.643\", \"r\")\n",
    "# f = open(\"ota_20.500.12024_0643\\\\0643\\\\ABODAT.643\")\n",
    "content = f.readlines()\n",
    "\n",
    "birbeck_list = []\n",
    "\n",
    "for line in content:\n",
    "    if(line.startswith('$')):\n",
    "        continue\n",
    "    pairs = line.strip().split(',')\n",
    "    # print(pairs)\n",
    "    for words in pairs:\n",
    "        if(len(words) > 0):\n",
    "              words = words.strip()\n",
    "              # print(words.split()[0])\n",
    "              birbeck_list.append(words)\n",
    "\n",
    "birbeck_list[110:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "p-4sqDBAcfGm"
   },
   "outputs": [],
   "source": [
    "# initializing variables\n",
    "\n",
    "birbeck_tokens={}\n",
    "correct_dict = collections.defaultdict(dict)\n",
    "MED = collections.defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "QHUYdLxpcMwv"
   },
   "outputs": [],
   "source": [
    "# to calculate Levenshtein distance between token 1 and token 2\n",
    "\n",
    "def levenshtein(token1, token2):\n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1))\n",
    "    for t1 in range(len(token1) + 1): distances[t1][0] = t1\n",
    "    for t2 in range(len(token2) + 1): distances[0][t2] = t2\n",
    "    a = 0; b = 0; c = 0\n",
    "\n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            a = distances[t1][t2 - 1]\n",
    "            b = distances[t1 - 1][t2]\n",
    "            c = distances[t1 - 1][t2 - 1]\n",
    "\n",
    "            if (a <= b and a <= c): distances[t1][t2] = a + 1\n",
    "            elif (b <= a and b <= c): distances[t1][t2] = b + 1\n",
    "            else: \n",
    "                if (token1[t1 - 1] == token2[t2 - 1]): distances[t1][t2] = c\n",
    "                else: distances[t1][t2] = c + 2\n",
    "\n",
    "\n",
    "            if(distances[t1][t2] > 10): \n",
    "                return\n",
    "\n",
    "#     print(token1, token2, distances[len(token1)][len(token2)])\n",
    "    MED[token1].update({token2 : int(distances[len(token1)][len(token2)])})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "_4eSo55VZZCa"
   },
   "outputs": [],
   "source": [
    "# Preprocessing Wordnet tokens to check if it is a number or other garbage value  \n",
    "\n",
    "def comparison(incorrect_token):\n",
    "    for word in wn.words():\n",
    "        if(word.startswith('.') or word[0].isdigit()):\n",
    "            continue\n",
    "        levenshtein(incorrect_token, word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147306\n"
     ]
    }
   ],
   "source": [
    "# words in Wordnet dictionary\n",
    "\n",
    "count_wn_words = 0\n",
    "for i in wn.words():\n",
    "    count_wn_words +=1\n",
    "print(count_wn_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CUtcePwjeHhX"
   },
   "outputs": [],
   "source": [
    "# to create argument list containing all incorrect spelling tokens for parallel processing and \n",
    "# to create a dictionary of incorrect word and the corresponding correct word\n",
    "\n",
    "birbeck_incorrect_tokens=[]\n",
    "\n",
    "def create_arg_list():\n",
    "    for idx in range(0,len(birbeck_list)):\n",
    "        birbeck_incorrect_tokens.append(birbeck_list[idx].split()[0])\n",
    "        correct_dict[birbeck_list[idx].split()[0]].update({birbeck_list[idx].split()[1] : 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Psti-bt2eNyE"
   },
   "outputs": [],
   "source": [
    "# call method\n",
    "\n",
    "create_arg_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('caugt', {'caught': 1}),\n",
       " ('choped', {'chopped': 1}),\n",
       " ('senery', {'scenery': 1}),\n",
       " ('tak', {'take': 1}),\n",
       " ('thougt', {'thought': 1})]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(correct_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thougt', \"wasen't\", 'abut', 'eweryone', 'leeiissy']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birbeck_incorrect_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "GXlZ6dUZH-Nm"
   },
   "outputs": [],
   "source": [
    "for i in birbeck_incorrect_tokens:\n",
    "    comparison(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "vHrxh904rG3d"
   },
   "outputs": [],
   "source": [
    "# multiprocessing pool object\n",
    "# pool = multiprocessing.Pool()\n",
    "\n",
    "# pool object with number of element\n",
    "# pool = multiprocessing.Pool(processes=4)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=5) as executor:\n",
    "        for result in executor.map(comparison, birbeck_incorrect_tokens):\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the calculated edit distances to json file\n",
    "\n",
    "import json\n",
    "\n",
    "with open('MED1.json', 'w') as fp:\n",
    "      json.dump(MED, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('MED1.json')\n",
    "\n",
    "MED = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(MED.items())[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionaries to store top k results k = {1, 5, 10} respectively and write to files in system\n",
    "\n",
    "sort_dict_10 = collections.defaultdict(dict)\n",
    "sort_dict_5 = collections.defaultdict(dict)\n",
    "sort_dict_1 = collections.defaultdict(dict)\n",
    "\n",
    "def sorted_dict_elements():\n",
    "    for i in MED:\n",
    "        sort_dict_10[i] =  (OrderedDict(sorted( MED[i].items(), key=itemgetter(1))[:10]))\n",
    "        sort_dict_5[i] =  (OrderedDict(sorted( MED[i].items(), key=itemgetter(1))[:5]))\n",
    "        sort_dict_1[i] =  (OrderedDict(sorted( MED[i].items(), key=itemgetter(1))[:1]))\n",
    "    with open('sort_dict.json', 'w') as fp:\n",
    "        json.dump(sort_dict_10, fp, indent=2)\n",
    "        json.dump(sort_dict_5, fp, indent=2)\n",
    "        json.dump(sort_dict_1, fp, indent=2)\n",
    "\n",
    "sorted_dict_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('caugt',\n",
       "  OrderedDict([('cut', 2),\n",
       "               ('aught', 2),\n",
       "               ('caput', 2),\n",
       "               ('cat', 2),\n",
       "               ('august', 3)])),\n",
       " ('choped',\n",
       "  OrderedDict([('chopped', 1),\n",
       "               ('choked', 2),\n",
       "               ('chapped', 3),\n",
       "               ('co-ed', 3),\n",
       "               ('cod', 3)])),\n",
       " ('senery',\n",
       "  OrderedDict([('scenery', 1),\n",
       "               ('eery', 2),\n",
       "               ('energy', 2),\n",
       "               ('sentry', 2),\n",
       "               ('beery', 3)])),\n",
       " ('tak',\n",
       "  OrderedDict([('ak', 1),\n",
       "               ('tack', 1),\n",
       "               ('taka', 1),\n",
       "               ('take', 1),\n",
       "               ('talk', 1)])),\n",
       " ('thougt',\n",
       "  OrderedDict([('thought', 1),\n",
       "               ('though', 2),\n",
       "               ('thou', 2),\n",
       "               ('thug', 2),\n",
       "               ('tout', 2)]))]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sort_dict_5.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating average using pytrec_eval \n",
    "\n",
    "results = collections.defaultdict(dict)\n",
    "\n",
    "for item in correct_dict:\n",
    "    results[item] = {}\n",
    "    \n",
    "    if(list(correct_dict[item].keys())[0] in sort_dict_1[item].keys()):\n",
    "        results[item][list(correct_dict[item])[0]] = 1\n",
    "    \n",
    "    for k in list(sort_dict_5[item].keys()):\n",
    "        if( k not in results[item].keys()):\n",
    "            results[item][k] = 1/5\n",
    "            \n",
    "    for k in list(sort_dict_10[item].keys()):\n",
    "        if( k not in results[item].keys()):\n",
    "            results[item][k] = 1/10    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = pytrec_eval.RelevanceEvaluator(correct_dict, {'success'})\n",
    "res = evaluator.evaluate(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(json.dumps(res, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average success_1 :  0.3577075098814229\n",
      "average success_10 :  0.5355731225296443\n",
      "average success_5 :  0.4901185770750988\n"
     ]
    }
   ],
   "source": [
    "for measure in sorted(list(res[list(res.keys())[0]].keys())):\n",
    "        print('average', measure, ': ', pytrec_eval.compute_aggregated_measure(measure, [query_measures[measure] for query_measures in eval.values()]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-assign-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
